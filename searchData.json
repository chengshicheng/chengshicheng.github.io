[{"title":"Selenium 爬虫总结","url":"/2019/12/15/spider-summary/","content":"## 1 前言\n最近由于项目需要，需要抓取网络上的一下数据，实现之后写个技术总结吧。其实我个人是不建议将爬虫接入到正式的项目中的，一来是有爬虫就有反爬虫，程序能稳定多久完全靠运气，网站的接口数据或页面格式稍有变动，爬虫就挂了，这种还是比较好解决的；一旦反扒机制升级，那就是噩梦的开始。二来其实会对服务器造成压力，如果爬取数据量大的话，一般网站也许就扛不住了，一旦造成服务器瘫痪，约等于网络攻击，最后一点。也是最重要的，爬虫可能是违法行为，这个取决于你爬取的数据类型和具体用途，也取决于对方想不想追究你的责任。总之一句话，且爬且珍惜。。。\n\n开始爬虫之前，有以下几个建议：\n\n1. 能通过接口拿到的，不要通过浏览器拿。爬虫的目的是要得到数据，能通过API直接拿到，不仅速度快，还不用解析界面。\n2. 不要只盯着PC端看，多看看移动端的网页或者API，会有惊喜。\n\n在确定要爬谁之前，先开个Fiddler,Charles等顺手的抓包工具，PC端，APP端，MobileWeb端，甚至小程序端，看一下能不到找带到现成的API。实在不行页面+API混着用也可以。接口需要认证权限的话还需要再寻找如何绕过去。\n\n一般来说，PC网页端的数据是最难爬的，反爬机制也是做的最好的，移动端的相对来说会弱很多。\n## 2 环境搭建\n\n在PhantomJS停止更新之后，selenium已经不建议使用PhantomJS了，建议使用chrome和firefox浏览器。如果是在自己电脑上运行的话，只要有浏览器就可以，如果要在服务器上运行的话，\n由于服务器没有安装桌面环境，所以浏览器只能运行在headless模式下，记录一下在Ubuntu Server安装浏览器的步骤：\n\n```shell\npip install selenium\n```\n在调用selenium启动浏览器的时候，需要指定浏览器的可执行文件路径，可以用webdriver_manager来替我们管理浏览器。\n```shell\npip install webdriver_manager\n```\n#### 2.1 chrome\n```shell\nwget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\nsudo dpkg -i google-chrome*.deb\n```\n如果环境依赖报错，执行以下命令：\n```shell\nsudo dpkg -i  --force-depends google-chrome*.deb  \nsudo apt-get install -f\n```\n\n#### 2.2 firefox\n```shell\nsudo apt-get install firefox\n```\n\n\n## 3 IP代理\n\n#### 3.1 设置代理\n- requests\n    ```python\n  proxies = {'http': f\"http://{host}:{port}\",\n               'https': f\"http://{host}:{port}\", }\n  s = requests.Session()\n  s.proxies.update(proxies)\n  url = 'http://www.baidu.com'\n  resp = s.get(url)\n    ```\n- selenium+chrome\n    ```python\n    from selenium import webdriver\n  \n    options =  webdriver.chrome.options.Options()\n    options.add_argument(f'--proxy-server=http://{host}:{port}')\n    driver = webdriver.Chrome(ChromeDriverManager().install(), chrome_options=options)\n    driver.get('http://www,baidu.com')\n    ```\n\n- selenium+firefox\n    ```python\n  from selenium import webdriver\n  from webdriver_manager.firefox import GeckoDriverManager\n  \n  fp = webdriver.FirefoxProfile()\n  # Direct = 0, Manual = 1, PAC = 2, AUTODETECT = 4, SYSTEM = 5\n  fp.set_preference(\"network.proxy.type\", 1)\n  fp.set_preference(\"network.proxy.http\", host)\n  fp.set_preference(\"network.proxy.http_port\", int(port))\n  fp.set_preference(\"network.proxy.ssl\", host)\n  fp.set_preference(\"network.proxy.ssl_port\", int(port))\n  fp.update_preferences()\n\n  driver = webdriver.Firefox(GeckoDriverManager().install(),\n                           firefox_profile=fp, options=options)\n  driver.get('http://www,baidu.com')\n    ```\n\n\n\n#### 3.2 匿名ip检验\n在设置代理后，可以访问一下页面，查看ip代理是否生效：http://myip.ipip.net/\n```python\n当前 IP：223.71.7.223  来自于：中国 广东 深圳  电信\n```\n\n到这一步还不够，真正的高匿名ip是不会暴露客户端的ip的。\n终极大杀器：http://httpbin.org/get?show_env=1\n\nHeader内容一览无余，不仅仅可以检验IP代理，还可以查看Header内容伪造是否成功\n```python\n{\n  \"args\": {\n    \"show_env\": \"1\"\n  }, \n  \"headers\": {\n    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\", \n    \"Accept-Language\": \"en,zh;q=0.9,zh-CN;q=0.8\", \n    \"Dccept-Encoding\": \"none\", \n    \"Dnt\": \"1\", \n    \"Host\": \"httpbin.org\", \n    \"Upgrade-Insecure-Requests\": \"1\", \n    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36\", \n    \"X-Forwarded-For\": \"223.71.7.223, 223.71.7.223\", \n    \"X-Forwarded-Port\": \"80\", \n    \"X-Forwarded-Proto\": \"https\", \n    \"X-Real-Ip\": \"223.71.7.223\"\n  }, \n  \"origin\": \"223.71.7.223, 223.71.7.223\", \n  \"url\": \"https://httpbin.org/get?show_env=1\"\n}\n```\n\n非高匿名IP代理请求，在Header中是会包暴露客户端IP的(X-Forwarded-For)，在Header中能同时看到客户端和代理的IP，我的代理是直接付费购买的，还没有遇到过这种情况。\n\n## 4 webdriver设置\n\n在PhantomJS停止更新之后，seleniums已经不建议使用PhantomJS了，不过新版chrome和firefox都支持了headless模式，下面的参数是我用到的，更多参数可以参考官方文档：\n\n#### 4.1 headlss模式\n- selenium+chrome\n    ```python\n  options = webdriver.chrome.options.Options()\n  options.add_argument('--headless')\n   driver = webdriver.Chrome(ChromeDriverManager().install(), chrome_options=options)\n\n    ```\n- selenium+firefox\n    ```python\n  options = webdriver.firefox.options.Options()\n  options.add_argument('--headless')\n  driver = webdriver.Firefox(options=options)\n    ```\n  或者\n  ```python\n  options = webdriver.firefox.options.Options()\n  options.headless = True  \n  driver = webdriver.Firefox(options=options)\n  ```\n  \n#### 4.2 不加载图片\n省去图片能够提高页面的加载速度\n- selenium+chrome\n```python\n# 1允许所有图片；2阻止所有图片；3阻止第三方服务器图片\noptions.add_experimental_option(\"prefs\", {\"profile.managed_default_content_settings.images\": 2,})\n\n```\n- selenium+firefox\n```python\noptions.set_preference('permissions.default.image', 2)\n```\n\n#### 4.3 设置user-agent\n我感觉修改这个用处不大，毕竟热门的useragent可能就那么多，就算反爬策略监测到了某个user-agent频繁请求，总不能给封了吧，封了之后其他正常用户还让不让用了。\n安装fake_useragent: `pip install fake_useragent`，或者自己存一点随机取。\n- selenium+chrome\n```python\nfrom fake_useragent import UserAgent\noptions.add_argument(f'user-agent={UserAgent().chrome}')\n```\n- selenium+firefox\n```python\nfp = webdriver.FirefoxProfile()\nfp.set_preference(\"general.useragent.override\", UserAgent().firefox)\ndriver = webdriver.Firefox(firefox_profile=fp)\n```\n\n#### 4.4 避免爬虫监测\n很多资料显示，selenium控制下的浏览器会被监测到，页面通过js代码获取到的`window.navigator.webdriver` 值不一样，正常手动打开的浏览器获取到的是`undefined`，而用selenium开启的浏览器是`true`。在浏览器中按下F12，点击console\n- 手动打开chrome\n```\n> window.navigator.webdriver\n< undefined\n```\n- selenium打开chrome\n```\n> window.navigator.webdriver\n< true\n```\n\n看来这个问题却是是存在的，至于网站有没有做这个监测，可以看一下js代码。很多资料都是用mitmproxy屏蔽js代码来绕过监测，实现起来也比较麻烦，不过对于chrome浏览器来说，设置成开发者模式就可以很轻松的解决，只需要一行代码\n```python\noptions.add_experimental_option('excludeSwitches', ['enable-automation'])\n```\n\n#### 4.5 其他设置\n- 等待时间，超时时间\n```python\ndriver = webdriver.xxxx()\ndriver.implicitly_wait(20)\ndriver.set_page_load_timeout(20)\n```\nimplicitly_wait是页面等待时长，经过实际验证，如果实际页面x秒(x<20)加载完成，则代码执行结束，否则页面继续等待加载至总时长（20秒）,才回执行后面的流程，\nset_page_load_timeout是超时时间，如果不设置，在find_element方法招不到对应元素的时候程序会一直卡住，所以这个参数一定要设置。\n\n\n## 5 元素解析\n推荐chrome插件xpath helper，鼠标往元素上一放就可以得到xpath，再也不用分析html层级了。本地开发调试时可以先关闭headless模式，可以直观看到页面数据\n\n## 6 其他\n以上示例中，每次新建一个webdriver都会新建一个浏览器窗口，所以代码每次处理完毕之后记得关闭浏览器，否则开多了系统内存也扛不住了。\n\n## 7 demo\n```python\nimport json\nimport time\nfrom selenium import webdriver\nfrom selenium.common.exceptions import NoSuchElementException, TimeoutException\nfrom webdriver_manager.chrome import ChromeDriverManager\nfrom fake_useragent import UserAgent\n\nhost = 'xxx.xx.xxx.xx'\nport = 'xx'\n\noptions = webdriver.chrome.options.Options()\noptions.add_argument('--headless')\noptions.add_argument('--no-sandbox')\noptions.add_argument('--disable-gpu')\n# 1允许所有图片；2阻止所有图片；3阻止第三方服务器图片\noptions.add_experimental_option(\"prefs\", {\n    \"profile.managed_default_content_settings.images\": 2,\n})\noptions.add_argument(f'user-agent={UserAgent().chrome}')\n# 开发者模式\noptions.add_experimental_option('excludeSwitches', ['enable-automation'])\n\n# 添加代理服务器信息\noptions.add_argument(f'--proxy-server=http://{host}:{port}')\ndriver = webdriver.Chrome(ChromeDriverManager().install(),\n                          chrome_options=options)\ndriver.implicitly_wait(20)\ndriver.set_page_load_timeout(20)  # 一定要设置超时时间,否则element找不到会一直卡死\ndata = {}\ntry:\n    driver.get('http://httpbin.org/get?show_env=1')\n    pre = driver.find_element_by_xpath(\"/html/body/pre\").text\nexcept NoSuchElementException as e1:\n    print(f'error,browser page:{driver.title}')\nexcept TimeoutException as e2:\n    print(f'webdriver time out')\nelse:\n    data = json.loads(pre)\nfinally:\n    #driver.delete_all_cookies()  # 清除浏览器cookie缓存\n    driver.quit()\n\nprint(data)\n```\n\n","tags":["python","爬虫"]},{"title":"Django自定义中间件","url":"/2019/11/16/django-mid/","content":"## 前言\nDjango中间件是一个常规的Python类，可插入Django的请求/响应生命周期。所有Django请求都会执行注册过的中间件中的方法，自定义的中间件需要继承Middleware类，并在项目设置中注册路径MIDDLEWARE_CLASSES。\n\n自定义中间件类应至少定义以下方法之一：\n\n-  在请求期间调用：\n\t- process_request(request)\n\t- process_view(request, view_func, view_args, view_kwargs)\n\t- process_exception（request，exception)\n\n-  在响应期间调用：\n\t- process_exception(request, exception) \n\t- process_template_response(request, response)\n\t- process_response(request, response)\n\n看方法名称就能看出来都是干什么的了，根据自己需要新建自定义类即可。\n\n## 中间件原理\n在整个请求到相应的过程中，会两次调用Middleware类，所以在设置的时候需要注意中间件的顺序，先看一下我当前项目设置的Middleware类：\n```python\nMIDDLEWARE_CLASSES = [\n    'corsheaders.middleware.CorsMiddleware',\n    'django.middleware.security.SecurityMiddleware',\n    'django.middleware.common.CommonMiddleware',\n]\n```\n在请求周期中，会**自上而下**的执行Middleware类，即首先执行CorsMiddleware类，依次执行到CommonMiddleware类，对于每个中间件，它都会执行process_request()和process_view()方法。\n接下来Django将会在view中执行，完成view应该完成的工作（查询数据库，分页，处理信息，逻辑处理等等），然后为客户端返回`Response`响应。\n\n在响应周期中，将**自下而上**执行Middleware类，即首先执行CommonMiddleware，最后执行 CorsMiddleware。同理，对于每个中间件，它将执行process_exception()，process_template_response()和process_response()方法。\n\n以上都执完毕之后，才回返回响应到客户端。下图是从Django官方文档中提取的，图解很形象。\n[![](https://docs.djangoproject.com/en/1.8/_images/middleware.svg)](https://docs.djangoproject.com/en/1.8/_images/middleware.svg)\n\n\n## 创建中间件类\n在我目前项目中，对于一些捕捉到的异常，是有用log记录异常信息的，但是没有捕捉到的exception，在非development环境中，是看不到的，所以打算加一个全局捕捉异常的中间件，用来trace 异常信息，方便快速定位问题。\n\n首先在lib文件夹下新建一个exception. py文件：\n```\nimport logging\nfrom django.utils.deprecation import MiddlewareMixin\nlogger = logging.getLogger(__name__)\n\nclass LogExceptionMiddleware(MiddlewareMixin):\n\n    def process_exception(self, request, exception):\n        import traceback\n        logger.error(traceback.format_exc())\n\n```\n\n接下来去`setting.py` 文件中添加`LogExceptionMiddleware`到Django中间件类集合中即可：\n```python\nMIDDLEWARE_CLASSES = [\n    ...\n    'lib.exeption.LogExceptionMiddleware'\n]\n\n```\n\n启动服务，随便抛个异常，就能在log文件中看到异常信息了。\n\n","tags":["django","python"]},{"title":"python网络通信：ctypes和struct使用总结","url":"/2019/09/21/ctypes-struct/","content":"\n最近项目组需要对接一个用C语言开发的so库，so库的函数主要功能是封装了一些socket通信的细节，以及数据加密。so的相关文档介绍了使用方式，主要流程如下：\n1. 初始化环境\n2. 创建socket\n3. 注册函数，socket的返回数据会通过这个函数返回\n4. 通过socket发送字节数据\n5. 接受返回数据，并解析处理\n\n第一次看的时候还是有点懵逼的，首先，动态库是C程序，这个函数是Python程序，C程序能够直接调用Python程序吗？其次，虽然这里不管是C还是Python都涉及到一些基本的数据类型，比如int型变量，C中的int和Python中的int是一样的吗？很显然，这两个问题的答案都是否定的，C程序没法直接调用Python函数，C中的整型和Python中的整型虽然都标记为int，但是两者是不一样的。\n\n这就是[`ctypes`](https://docs.python.org/3.6/library/ctypes.html)库存在的原因了，我们都知道Python是用C语言开发的，具体内部实现细节我们不得而知，但是像上面提到的，int,string等基本的数据类型，如何和C对应起来，要知道C中的类型可比Python复杂多了。ctypes库作为C和Python之间的桥梁，让Python程序也可以和C语言交互了。\n\n## ctypes使用\n\n### 数据类型对应\nctypes定义了许多基本的C兼容数据类型：\n\nctypes type     | C type                                  | Python type\n---             | ---                                     | ---\nc_bool          | _Bool                                   | bool (1)\nc_char          | char                                    | 1-character bytes object\nc_wchar\t        | wchar_t\t                              | 1-character string\nc_byte\t        | char\t                                  | int\nc_ubyte\t        | unsigned char\t                          | int\nc_short\t        | short\t                                  | int\nc_ushort\t    | unsigned short\t                      | int\nc_int\t        | int\t                                  | int\nc_uint\t        | unsigned int\t                          | int\nc_long\t        | long\t                                  | int\nc_ulong\t        | unsigned long\t                          | int\nc_longlong\t    | __int64 or long long\t                  | int\nc_ulonglong\t    | unsigned __int64 or unsigned long long  | int\nc_size_t\t    | size_t\t                              | int\nc_ssize_t\t    | ssize_t or Py_ssize_t\t                  | int\nc_float\t        | float\t                                  | float\nc_double\t    | double\t                              | float\nc_longdouble\t| long double\t                          | float\nc_char_p\t    | char * (NUL terminated)                 | bytes object or None\nc_wchar_p\t    | wchar_t * (NUL terminated)              | string or None\nc_void_p\t    | void *\t                              | int or None\n\n\n\n### 加载so  \nPython通过ctypes加载so有两种方式，如果so文件不在系统环境变量路径中，也可以使用相对路径或者绝对路径来加载，`libc.so.6` 库是linux系统中自带的c函数库，常用的c函数都能通过它调用。\n```python\n>>> from ctypes import *\n>>> libc = CDLL(\"libc.so.6\") \n>>> libc\n<CDLL 'libc.so.6', handle 7fb8246af000 at 0x7fb823860940>\n>>> \n>>> libc=cdll.LoadLibrary(\"/usr/lib/libc.so.6\")\n>>> libc\n<CDLL '/usr/lib/libc.so.6', handle 7f6d0ff77000 at 0x7f6d0f129710>\n```\n\n### 函数调用\n```python\n>>> func=libc.printf\n>>> func\n<_FuncPtr object at 0x7f2320a594f8>\n>>> result = func(c_char_p('hello'))\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: bytes or integer address expected instead of str instance\n>>> \n>>> result = func(c_char_p('hello'.encode()))\nhello>>> \n>>> result\n5\n```\nC的printf()函数接收字节数组的指针`char *`，对应ctypes中的`c_char_p`，直接传入字符串会报错，提示传入`bytes`，转化后成功输出。\n\n总而言之，C类型接收什么类型的参数，Python调用时用ctypes内置的方法转换一下就可以了。其实有一些不用转换也可以直接调用，比如int类型：\n\n```python\n>>> libc.abs(-100)\n100\n```\n\n\n### 指定参数类型\n\n在调用C函数时，可以通过前置的指定类型方法，为我们检查数据格式是否正确，比如有这样一个函数：\n```c\nint CSend_message(char *data,int len)\n```\n入参分别是需要发送的参数，和参数长度，返回值是int类型，代表是否发送成功。在Python中可以用`argtypes`和`restype`来指定其入参和返回值的类型，ctypes会为我们检查输入的参数类型是否正确：\n\n```python\n>>> data = 'to_send_data'.encode()\n>>> \n>>> so = CDLL(\"xxx.so\") \n>>> csend = so.CSend_message\n>>> csend.argtypes = [c_char_p, c_int]\n>>> csend.restype = c_int\n>>> result = csend(data, len(data))\n\n```\n\n当然简单的参数我觉得是用不上这些的，在比较复杂的情况下，还是比较试用的，比如这个：\n```c\nint CSign(unsigned char sourcedata[],unsigned long sourcedataLen,\n          unsigned char targetdata[],unsigned long &targetdataLen);\n          \n参数说明：\n\n1. sourcedata 未签名的数据    \n2. sourcedataLen 未签名数据长度    \n3. targetdata 已签名数据 \n4. targetdataLen 已签名数据长度的地址 \n```\n\n将要加密的参数Sourcedata传入后，该方法会将加密后的128字节的数据存入targetdata所在的内存地址中，要想拿到加密结果，需要我们自己从该地址中读取，这里随意初始化一个128字节的字节数组传入即可：\n\n```python\n>>> data = 'to_sign_data'.encode()\n>>> length = len(data)\n>>> source = tuple(z for z in data)\n>>> source_data  = (c_ubyte * length)(*source)\n>>> source_data\n<__main__.c_ubyte_Array_12 object at 0x7f2320ab29d8>\n>>> \n>>> target_data = (c_ubyte * 128)(1)\n>>> target_data\n<__main__.c_ubyte_Array_128 object at 0x7f2320a7eae8>\n>>> \n>>> sign = so.CSign\n>>> sign.argtypes = [c_ubyte * length, c_ulong,\n                     c_ubyte * 128, c_ulong]\n>>> sign.restype = c_int\n>>> sign(source_data, c_ulong(length),\n         target_data, c_ulong(addressof(c_int(128)))\n         )\n```\n\n### 地址取值\n上面的加密程序执行之后，需要从`target_data` 所在的内存地址中取值。ctypes中的取值我用到了两种，\n一种是根据内存地址来取值，一种是根据指针来取值，其实可以总结为一种，因为指针指向的就是一个内存地址。\n\n- 通过`addressof`方法可以获取ctypes对象的内存地址，再通过`string_at()`取出固定大小的数据\n   从内存地址取值：\n    ```python\n    string_at(addressof(target_data), 128)\n    ```\n- 通过`cast`方法将ctypes对象转化为指针对象，再用`string_at()`取出数据\n    ```python\n    data_p = cast(target_data, c_char_p)\n    string_at(data_p, 128)\n    ```\n\n### 回调函数\n\n#### 创建回调函数\n上面提到socket发送数据之后，server端的数据会通过回调函数返回，文档中对回调函数的定义如下，返回两个参数，第一个是指向数据的指针，第二个是数据的长度：\n\n```c\nint (CALLBACK *ReadCallback)(char *data, int len)\n```\n\n根据要求在Python中新建回调函数：\n```python\ndef callback(data_p, len):\n    message = string_at(data_p, len)\n    parse_message(message)\n    return 0\n```\n\n函数也很简单，就是从指针地址中取出数据，并调用数据解析函数，返回值为int。\n\n#### 注册回调函数\n\n在创建socket客户端的时候，输入服务器的ip和端口，同时传入回调函数，C函数定义如下\n```c\nint CCreate_socket(ReadCallback readcallback,char *ip,u_short port);\n```\n\n在ctypes中，通过关键字 `CFUNCTYPE` 来声明一个回调函数的类型，通过关键字的字面意思也能够看出来，C-FUNC-TYPE，那就是C语言的函数（FUNC）类型（TYPE）。\n```python\nCMPFUNC = CFUNCTYPE(c_int, c_char_p, c_int)\n```\n眼尖的同学可能已经发现了，上面不是求只要获得回传参数的指针和长度么，这里声明回调函数类型的时候怎么变成了三个参数？其实吧，这里只是指的数据类型，并不是参数本身，后面两个 `c_char_p`和`c_int` 指的是传递给 `callback` 回调函数的参数类型，第一个 `c_int` 指的是回调函数的返回值类型。只有这样定义，C程序才能认识。\n\npython相关的代码如下：\n```python\nsocket = ukey.CCreate_socket\nsocket.argtypes = [CMPFUNC, c_char_p, c_ushort]\nsocket.restype = c_int\nc = socket(CMPFUNC(callback), ip, port)\n```\n\n\n## struct打包拆包\n\nstruct是python用来组包解包常用的包，在网络通信中，所有的数据都会通过字节流的方式传输，比如常用的 `https` ，只不过这些通信协议帮我们实现了底层的数据拼接和发送的细节，让开发者只需要关注应用层的业务逻辑。在`socket`通信中，一般都是开发者自定义协议规则。\n\n在ctypes的数据类型对应表中，可以看到C中的数据类型很多，Python中的一个`int`的数据，在组包发送的时候，需要对应C中的哪一种数据类型，到底应该填充几个字节呢？在协议定好的基础上，通过struct可以轻松定义。使用比较简单，只需要掌握`字节序` 和 `字符格式` 两点。\n\n\n#### 字节序\n对于多字节数据，由于在内存中的存储方式的不同，可以分为`大端` 和 `小端`模式；默认情况下，C类型以机器的本机格式和字节顺序表示， struct可以指定具体用哪种模式：\n\n\nCharacter  | Byte order                  | Size\n---        | ---                         | ---\n@          | native                      | native\n=          | native                      | standard  \n<          | little-endian               | standard \n>          | big-endian                  | standard\n!          | network (= big-endian)      | standard\n\n\n#### 字符格式\n\n格式字符具有以下含义；C 和 Python值之间的按其指定类型的转换应当是直接定义具体类型，每种类型的标准大小，就是打包后占用的字节个数：\n\n\n格式        | C类型                | Python类型 | 标准大小 | 注释\n---        | ---                  | ---       | ---    | ---\nx          | 填充字节               | 无         | 1     |  (1),(3)\nc          | char       | 长度为 1 的字节串 | 1   |  (3)\nb          | signed char        | 整数 | 1   |  (1)\nB          | unsigned char      | 整数 | 1   |  (3)\n?          | _Bool      | bool | 2   |  (3)\nh          | short      | 整数 | 2   |  (3)\nH          | unsigned short     | 整数 | 4   |  (3)\ni          | int        | 整数 | 4   |  (3)\nI          | unsigned int       | 整数 | 4   |  (3)\nl          | long       | 整数 | 4   |  (2), (3)\nL          | unsigned long      | 整数 | 8   |  (2), (3)\nq          | long long      | 整数 | 8   |  (4)\nQ          | unsigned long long     | 整数 |    |  (4)\nn          | ssize_t        | 整数 |    |  (5)\nN          | size_t     | 整数 | 2   |  (5)\ne          | (7)        | 浮点数 | 4   |  (5)\nf          | float      | 浮点数 | 8   |  \nd          | double     | 浮点数 |    |  \ns          | char[]     | 字节串 |    |  (6)\np          | char[]     | 字节串 |    |  \nP          | void *     | 整数 |    |  \n\n\n#### pack/unpack示例\n`pack`进行打包，`unpack`进行解包，`calcsize` 用于计算字符格式的大小。常用的就是这3个方法。\n\n\n\n小端模式打包解包`short`、 `unsigned int`和`unsigned long`三个数据:\n```python\n>>> import struct\n>>> struct.pack('<hIL',1,2,3)\nb'\\x01\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00'\n>>> struct.unpack('<hIL',b'\\x01\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00')\n(1, 2, 3)\n>>> struct.calcsize('hIL')\nstr(    struct  \n>>> struct.calcsize('<hIL')\n10\n>>> \n```\n\n大小端的区别：\n```python\n>>> struct.pack('<L', 1)\nb'\\x01\\x00\\x00\\x00'\n>>> struct.pack('>L', 1)\nb'\\x00\\x00\\x00\\x01'\n>>> \n```\n\n格式字符的顺序可能对大小产生影响，因为满足对齐要求所需的填充是不同的:\n```python\n>>> struct.pack('ci', b'*', 7654321)\nb'*\\x00\\x00\\x00\\xb1\\xcbt\\x00'\n>>> struct.pack('ic', 7654321, b'*')\nb'\\xb1\\xcbt\\x00*'\n>>> struct.calcsize('ci')\n8\n>>> struct.calcsize('ic')\n5\n```\n\n格式字符的标准大小会对大小产生影响，区别于是数据的标准大小还是原生大小：\n```python\n>>> struct.calcsize('<hIL')\n10\n>>> struct.calcsize('@hIL')\n16\n```\n\n多个连续的可以在前面加数字，`hhh` 等于 `3h`：\n```python\n>>> struct.pack('hhh', 1,2,3)\nb'\\x01\\x00\\x02\\x00\\x03\\x00'\n>>> struct.pack('3h', 1,2,3)\nb'\\x01\\x00\\x02\\x00\\x03\\x00'\n>>> \n```\n\nstruct还有`pack_into` 和`unpack_from` 用于从固定offset来处理数据，用的不多在这里就不在介绍了。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["python"]},{"title":"Linux gcc编译动态、静态链接库","url":"/2019/09/07/gcc-so/","content":"\n\n# 库的分类\n\n### 动态链接库\n动态库的链接是在程序执行的时候被链接的。所以，即使程序编译完，依赖库仍须保留在系统上，以供程序运行时调用。如果依赖库文件找不到了，动态链接库就无法正常运行了。\n\n###  静态链接库\n静态链接库不受依赖库的影响，即使依赖库被删除了，程序依然可以运行成功。\n\n\n两种库文件应该是各有利弊，静态链接库的本质其实是赋值粘贴的过程，编译过程中会将所使用的库文件一起打包嵌入到可执行文件中。相比之下，链接动态库的程序体积会小很多。\n\n接下类将分别编译静态和动态库，最后动手看看具体有什么区别。首先新建`static` 和`dynamic`文件夹，用于存放各自代码。\n\n\n# 编译动态库\n进入 `dynamic` 文件夹，新建 `add.c` 文件：\n\n```c\n#include <stdio.h>\n\nint add(int a,int b)\n{\n\tint c;\n\tc = a+b;\n   \tprintf(\"from c add() : %d\\n\",c);\n   \treturn c;\n}\n```\n运行以下命令编译，会生成 `libadd.so` 文件：\n\n```\ngcc -fPIC -shared add.c -o libadd.so\n```\n实际上上述过程分为编译和链接两步：\n\n-fPIC是编译选项，PIC是 Position Independent Code的缩写，表示要生成位置无关的代码，这是动态库需要的特性； \n\n-shared是链接选项，告诉gcc生成动态库而不是可执行文件。\n\n上述的一行命令等同于下面两个命令，第一行是把 `add.c` 编译成可执行文件 `add.o`, 如果在C程序中加入 `main()` 函数，是可以直接运行 `add.o` 文件的；第二行是通过 `-shared` 参数将 `add.o` 实现动态链接，得到 `libadd.so` 。\n```\ngcc -c -fPIC add.c\ngcc -shared -o libadd.so add.o\n```\n\n接下来我们将新建 `test.c` 来测试刚刚生成的动态链接库\n首先创建 `add.h` 头文件\n\n```c\nvoid add();\n```\n\n写入测试程序到 `test.c` ：\n\n```\n#include <stdio.h>\n#include \"add.h\"\n \nint main(){\n\tprintf(\"call add in test.c\\n\");\n\tadd(2,3);\n}\n```\n\n编译 `test.c` 文件：\n\n```\ngcc test.c -L. -ladd -o test\n```\n-L的选项是指定编译器在搜索动态库时搜索的路径，告诉编译器 `add.so`库的位置。\".\"意思即当前路径，如果不指定，编译器会找不到依赖库而报错\n\n```\n➜  dynamic gcc test.c -ladd -o test\n/usr/bin/ld: 找不到 -ladd\ncollect2: 错误：ld 返回 1\n```\n\n-l选项是因为\nLinux下的库文件在命名时有一个约定，就是应该以 lib 这3个字母开头，由于所有的库文件都遵循了同样的规范，因此在用 -l 选项指定链接的库文件名时可以省去 lib 这3个字母。例如，gcc 在对 `-ladd ` 进行处理时，会自动去`-L` 指定的文件夹下链接名为 `libadd.so` 的文件。\n\n编译完成后，文件夹下有以下文件：\n\n```zsh\n➜  dynamic ls\nadd.c  add.h  libadd.so  test  test.c\n```\n\n我们刚刚在 `test.c`文件中是定义了 `main()` 函数的，此时编译后的 `test` 应该是可以直接运行的。\n\n```\n➜  dynamic ./test\n./test: error while loading shared libraries: libadd.so: cannot open shared object file: No such file or directory\n➜  dynamic ldd test.so\n\tlinux-vdso.so.1 (0x00007ffc859df000)\n\tlibadd.so => not found\n\tlibc.so.6 => /usr/lib/libc.so.6 (0x00007f72e33fb000)\n\t/lib64/ld-linux-x86-64.so.2 => /usr/lib64/ld-linux-x86-64.so.2 (0x00007f72e35fb000)\n➜  dynamic\n```\n\n报错信息提示找不到` libadd.so` 文件，通过 `ldd` 命令查看依赖库时也提示未找到，最简单的方式是将依赖库文件拷贝到系统目录：\n\n```\n➜  dynamic  sudo cp libadd.so /usr/lib\n[sudo] chengshicheng 的密码：\n➜  dynamic \n➜  dynamic ./test\ncall add in test.c\nfrom c add() : 5 \n➜  dynamic \n```\n\n这样，再次执行就成功了，可以看到在`main()` 函数中调用了`libadd.so`动态库中的方法，并计算成功。\n\n\n# 编译静态库\n\n静态库代码和动态库基本一样,只是gcc编译命令参数和动态链接库的有一些差别。先进入 `static` 文件夹，新建 `add.c` 文件：\n\n```c\n#include <stdio.h>\n\nint add(int a,int b)\n{\n\tint c;\n\tc = a+b;\n   \tprintf(\"from c add() : %d\\n\",c);\n   \treturn c;\n}\n```\n\n编译 `add.c` 文件，会生成 `add.o`文件，注意到这里和编译动态链接库时的命令就是少了`-fPIC`参数：\n\n```\ngcc -c add.c\n```\n生成静态库\n\n```\nar -r libadd.a add.o\n```\n\n现在可以开始测试刚刚生成的静态链接库 `libmyadd.a`，首先新建 `add.h`头文件：\n\n\n```\nvoid add();\n```\n然后新建测试文件 `test.c` ：\n\n```\n#include <stdio.h>\n#include \"add.h\"\n \nint main(){\n\tprintf(\"call add in test.c\\n\");\n\tadd(3,5);\n}\n```\n编译运行\n```zsh\n➜  static gcc test.c -ladd -L. -static -o test\n➜  static ls\nadd.c  add.h  add.o  libadd.a  test  test.c\n➜  static ./test\ncall add in test.c\nfrom c add() : 8\n➜  static \n````\n\n要验证依赖库确实是静态库，我们移除静态库   `libadd.a` 文件试试看：\n\n```zsh\n➜  static mv libadd.a libadd.a.back\n➜  static ls\nadd.c  add.h  add.o  libadd.a.back  test  test.c\n➜  static ./test \ncall add in test.c\nfrom c add() : 8\n➜  static \n\n```\n\n以上，静态链接库经过验证之后没有问题。上文中我们提到过链接静态库会比动态的文件体积大，那我们来对比下，直接上数据：\n\n```\n➜  static ll\n总用量 764K\n-rw-r--r-- 1 chengshicheng chengshicheng  114  9月  6 00:59 add.c\n-rw-r--r-- 1 chengshicheng chengshicheng   13  9月  6 01:10 add.h\n-rw-r--r-- 1 chengshicheng chengshicheng 1.6K  9月  6 01:21 add.o\n-rw-r--r-- 1 chengshicheng chengshicheng 1.7K  9月  7 00:14 libadd.a.back\n-rwxr-xr-x 1 chengshicheng chengshicheng 743K  9月  7 00:21 test\n-rw-r--r-- 1 chengshicheng chengshicheng   96  9月  6 01:09 test.c\n➜  static ll ../dynamic \n总用量 48K\n-rw-r--r-- 1 chengshicheng chengshicheng 114  9月  6 00:46 add.c\n-rw-r--r-- 1 chengshicheng chengshicheng  12  9月  5 23:56 add.h\n-rwxr-xr-x 1 chengshicheng chengshicheng 16K  9月  6 00:46 libadd.so\n-rwxr-xr-x 1 chengshicheng chengshicheng 17K  9月  7 00:18 test\n-rw-r--r-- 1 chengshicheng chengshicheng  96  9月  6 00:46 test.c\n```\n可以看到，在源文件`add.c` 、`add.h` 、`test.c` 三个文件大小一致的前提下，最终打包出来的`test` 可执行文件，链接静态库和链接动态库的文件体积相差了近`44`倍！\n\n\n# 总结\n通过以上对比，对链接两种不同的库文件的区别也有了一定的了解，其实并不存在优劣的区别；根据场景，我们可以选择不同的方案，比如使用动态链接库时，需要运行环境中存在对应的库文件，如果使用静态库就不存在这个问题，更方便调用者使用。\n\n\n\n","tags":["Linux","gcc"]},{"title":"Python编译so","url":"/2019/09/01/python-so/","content":"\nPython的解释特性是将py编译为独有的二进制编码pyc文件，然后对pyc中的指令进行解释执行，但是pyc的反编译却非常简单，可直接反编译为源码，当需要将产品发布到外部环境的时候，源码的保护尤为重要。\n\n基于以上原因，本文将介绍如何将python源码编译pyc，编译成动态链接库.so文件并使用。环境为 [Linux manjaro](https://manjaro.org/)，python版本为3.7，gcc版本为9.1.0。\n\n# py文件打包为so\n\n首先在test目录下新建add.py文件,写入测试代码:\n\n```python\ndef add(a,b):\n    result = a+b\n    print(f'{a}+{b}={result}')\n    return result\n```\n\n新建setup.py文件:\n```python\nfrom distutils.core import setup\nfrom Cython.Build import cythonize\n\nsetup(ext_modules=cythonize([\"add.py\"]))\n```\n\n然后执行以下命令\n\n```bash\npython setup.py build_ext\n```\n新的目录结构为:\n\n```bash\n➜  test tree\n.\n├── add.c\n├── add.py\n├── build\n│   ├── lib.linux-x86_64-3.7\n│   │   └── add.cpython-37m-x86_64-linux-gnu.so\n│   └── temp.linux-x86_64-3.7\n│       └── add.o\n└── setup.py\n```\n新生成的build/lib*/add.*.so目录下的就是我们想要的，直接开始测试：\n\n```bash\n➜  test cd build/lib.linux-x86_64-3.7 \n➜  lib.linux-x86_64-3.7 python\nPython 3.7.3 (default, Jun 24 2019, 04:54:02) \n[GCC 9.1.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import add\n>>> c = add.add(1,2)\n1+2=3\n>>> c\n3\n```\n\n由python代码编译成的so，是可以直接当成模块import使用的，如果是其他语言呢？在test根目录下，除了新生成的build文件夹之外，在根目录生还生成了add.c文件，其实编译so的过程，就是cpython帮我们把python代码翻译成c语言的代码,再由gcc编译成so动态链接库。\n\n下一篇将讲解如何用gcc将.c文件编译成动态链接库。\n\n\n\n\n\n","tags":["python","so"]},{"title":"MongoDB 安全防护","url":"/2019/08/21/mongo_safe/","content":"\nMongoDB 是一个高性能，开源，无模式的文档型数据库，是当前noSql数据库产品中最热门的一种。然而MongoDB部署之后的安全性却容易被忽视，其默认配置会让你的数据库处于裸奔状态，没有任何认证，直接暴露在公网里。MongoDB “[赎金事件](https://www.4hou.com/info/news/7581.html)”便由此引起。\n\n针对上述情况，国家网络与信息安全信息通报中心建议采取以下防范措施：\n- 一是修改数据库默认端口或将数据库部署在内网环境中，将MongoDB数据库默认端口（TCP 27017）修改为其他端口；\n- 二是开启MongoDB数据库访问授权；\n- 三是使用SSL加密功能；\n- 四是使用“--blind_ip”选项，限制监听接口IP；\n- 五是开启数据库日志审计功能，记录所有数据库操作；\n- 六是及时做好重要数据备份工作。\n\n## 修改部署环境\n```\nvim /etc/mongo.conf\n\n# network interfaces\nnet:\n  port: 27017\n  bindIp: 0.0.0.0\n```\n\n默认端口是27017 ，修改成其他空闲端口即可。需要注意此处的bingIP是指这个mongo的服务端绑定的IP，并不是网上流传的用来限制哪些client的IP去访问。bindIP默认是0.0.0.0本机地址，任意主机都可访问MongoDB 。\n#### 本机部署\nbindIp 设置为127.0.0.1，只有本机连接数据库。\n#### 内网部署\n假如你服务器是阿里云的服务器，一般会有内网ip和外网ip，通过绑定内网IP+阿里云自带的ECS安全组，可以直接将MongoDB与外部网络阻断。\n#### 外网部署\n尽量避免静数据库暴露在公网，如果业务场景需要，建议部署一套VPN，远程只能通过VPN网络隧道进行连接，可以最大程度避免攻击。\n\n## 访问校验和访问控制\n\n```\nvim /etc/mongo.conf\n\nsecurity:\n    authorization: disabled\n```\n访问校验功能需要所有的客户端在连接MongoDB数据库的时候提供凭据，MongoDB提供db.auth()方法进行验证，在使用mongo shell命令的时候，可以在控制台输入验证信息。\n访问控制可以给指定用户创建不同db的多种权限组合，不同用户访问不同的db，并赋予各自的读写权限。解决步骤如下：\n- 关闭权限验证、启动MongoDB\n- 创建MongoDB超级管理员，给予最高权限\n- 分别创建用户，给予各自db的权限\n- 开启权限验证、启动MongoDB\n- 测试\n#### 启动MongoDB\nMongoDB默认是关闭访问校验功能的，只需要启动MongoDB服务就行\n#### 创建管理员\n创建管理员的相关操作都必须先切换到admin库，然后执行createUser命令：\n```\nmongo\n\n> use admin\nswitched to db admin\n> db.createUser({user:\"root\",pwd:\"123rootpwd\",roles:[{role:\"userAdminAnyDatabase\",db:\"admin\"}]})\nSuccessfully added user: {\n\t\"user\" : \"root\",\n\t\"roles\" : [\n\t\t{\n\t\t\t\"role\" : \"userAdminAnyDatabase\",\n\t\t\t\"db\" : \"admin\"\n\t\t}\n\t]\n}\n```\n\n键入以下命令，可以查看创建结果：\n````\nshow users\n````\n\n#### 创建用户\n````\n> use db1\nswitched to db db1\n> db.createUser({user:\"testUser\",pwd:\"123456\",roles:[{role:\"readWrite\",db:\"db1\"}]})\nSuccessfully added user: {\n\t\"user\" : \"testUser\",\n\t\"roles\" : [\n\t\t{\n\t\t\t\"role\" : \"readWrite\",\n\t\t\t\"db\" : \"db1\"\n\t\t}\n\t]\n}\n````\n上面的命令创建了用户名为testUser的用户，拥有db1的读写权限，更多的用户管理操作可以参考[官方文档](https://docs.mongodb.com/manual/reference/method/js-user-management/)，方便随时修改用户权限。\n#### 开启认证，重启MongoDB\n将配置文件中的authorization修改为enable，重启数据库服务。后续所有的数据库操作都需要校验，否则数据库会报错，需要调用db.auth()认证通过后，才能执行MongoDB shell 命令。\n\n````\n➜  blog # mongo \nMongoDB shell version v4.0.4\nconnecting to: mongodb://127.0.0.1:27017\nImplicit session: session { \"id\" : UUID(\"3a76953f-de87-4845-a848-e7ff4b7bb9bb\") }\nMongoDB server version: 4.0.4\n> use db1\nswitched to db db1\n> show dbs;\n2019-08-16T22:05:50.034+0800 E QUERY    [js] Error: listDatabases failed:{\n\t\"ok\" : 0,\n\t\"errmsg\" : \"command listDatabases requires authentication\",\n\t\"code\" : 13,\n\t\"codeName\" : \"Unauthorized\"\n} :\n_getErrorWithCode@src/mongo/shell/utils.js:25:13\nMongo.prototype.getDBs@src/mongo/shell/mongo.js:67:1\nshellHelper.show@src/mongo/shell/utils.js:876:19\nshellHelper@src/mongo/shell/utils.js:766:15\n@(shellhelp2):1:1\n> \n> db.auth('testUser','wrongpasswd')\nError: Authentication failed.\n0\n> db.auth('testUser','123456')\n1\n> show dbs;\ndb1  0.000GB\n````\n\n## SSL加密\n\n还没有配置，后面在更。\n## 日志记录\n配置文件详解：\n```\nsystemLog:\n   verbosity: 1  #日志等级，0-5，默认0\n   # quiet: false  #限制日志输出，\n   traceAllExceptions: true  #详细错误日志\n   # syslogFacility: user #记录到操作系统的日志级别，指定的值必须是操作系统支持的，并且要以--syslog启动\n   path: /var/log/mongodb/mongod.log  #日志路径。\n   logAppend: true\n   logRotate: rename #rename/reopen。rename，重命名旧日志文件，创建新文件记录；reopen，重新打开旧日志记录，需logAppend为true\n   destination: file\n   timeStampFormat: iso8601-local\n   # component: #各组件的日志级别\n   #    accessControl:\n   #       verbosity: <int>\n   #    command:\n   #       verbosity: <int>\n```\n将日志输出到文件后，可以通过查看文件跟踪数据库启动及运行错误，以便MongoDB出现异常时，及时定位问题并修复。\n## 数据备份\n#### 备份(mongodump)\nMongodb中我们使用mongodump命令来备份MongoDB数据。该命令可以导出所有数据到指定目录中：\n```\nmongodump -h 127.0.0.1:27017 -d db1 -c books -o /var/db/dump/2019-08-17/db1/books/\n```\n一般在备份服务器上，会用脚本文件定时dump数据，需要考虑到多db(-d参数)、多集合(-c参数)的备份。为了避免数据过多占用磁盘空间，还需要能够及时删除旧的备份。\n#### 恢复(mongorestore)\n```\nmongorestore -h 127.0.0.1:27017 -d db1 -c books /var/db/dump/2019-08-17/db1/books/\n```\n最后一个参数就是要恢复的数据文件夹或文件，当需要还原时，可以根据情况对某些数据进行还原。希望我永远用不到这个命令。\n\n\n\n\n\n\n","tags":["mongo"]},{"title":"Hello World","url":"/2019/08/20/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n\n","tags":["mongo"]}]